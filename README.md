# PipelineAnalytics
Application simulates streaming data to create pretty graphs using Google Data Studio.

## Why?
With so much data being transmitted, there's an increased demand in data analytics.
This project explores a simple pipeline method that uses the following:
- Custom data generator to simulate streaming data
- Google pub/sub to aggregate and collect data
- Custom data processing to analyze data
- Google BigQuery to store analyzed data
- Google Data Studio to aggregate and display data in the form of pretty charts/graphs

## How Do I Run This?
For starters, you'll want to make sure you have everything Google Cloud related setup.
This includes:
- Google pub/sub with a topic and subscription
- Google BigQuery table
- Google Data Studio (linked to BigQuery)
- Proper authentication setup in you development environment
- Proper billing on Google Cloud setup (space isn't free!)

Once you have that all setup, modify the global variables in `generator.py` to match your pub/sub names.
You will also wanna modify `pipelineanalytics.py` to match your project name.

Once all that is done, just run `generator.py` and `pipelineanalytics.py` and voila!
You won't have pretty graphs yet (since you need to drag and drop them in Data Studio), but BigQuery should start getting populated.

## Drawbacks + Possible Future Projects
One of the obvious drawbacks is using the custom data processing to analyze incoming data.
It's simply not scalable (especially if we're talking about large datasets), and isn't very robust.
However, using tools like Google Dataflow or AWS Kinesis was beyond the scope of this project.
In the future, however, I'd like to use a fully-functional robust pipeline that analyzes meaningful data (AKA not generated by me).
Who knows? Maybe it'll show some interesting trends.